{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # 导入Numpy\nimport pandas as pd # 导入Pandas\nimport os # 导入os工具\nprint(os.listdir(\"../input/stanford-dogs-dataset/images/Images\"))","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:15.669634Z","iopub.execute_input":"2021-12-08T16:16:15.669931Z","iopub.status.idle":"2021-12-08T16:16:15.729969Z","shell.execute_reply.started":"2021-12-08T16:16:15.669849Z","shell.execute_reply":"2021-12-08T16:16:15.728829Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 本示例咱只处理这10种狗吧\ndir = '../input/stanford-dogs-dataset/images/Images/' \nchihuahua_dir = dir+'n02085620-Chihuahua' #吉娃娃\njapanese_spaniel_dir = dir+'n02085782-Japanese_spaniel' #日本狆\nmaltese_dir = dir+'n02085936-Maltese_dog' #马尔济斯犬\npekinese_dir = dir+'n02086079-Pekinese' #北京狮子狗\nshitzu_dir = dir+'n02086240-Shih-Tzu' #西施犬\nblenheim_spaniel_dir = dir+'n02086646-Blenheim_spaniel' #英国可卡犬\npapillon_dir = dir+'n02086910-papillon' #蝴蝶犬\ntoy_terrier_dir = dir+'n02087046-toy_terrier' #玩具猎狐梗\nafghan_hound_dir = dir+'n02088094-Afghan_hound' #阿富汗猎犬\nbasset_dir = dir+'n02088238-basset' #巴吉度猎犬","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:15.732247Z","iopub.execute_input":"2021-12-08T16:16:15.732681Z","iopub.status.idle":"2021-12-08T16:16:15.740979Z","shell.execute_reply.started":"2021-12-08T16:16:15.732637Z","shell.execute_reply":"2021-12-08T16:16:15.739873Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import cv2 # 导入Open CV工具箱\nX = []\ny_label = []\nimgsize = 150\n# 定义一个函数读入狗狗图片\ndef training_data(label,data_dir):\n    print (\"正在读入：\", data_dir)\n    for img in os.listdir(data_dir):\n        path = os.path.join(data_dir,img)\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img,(imgsize,imgsize))\n        X.append(np.array(img))\n        y_label.append(str(label)) \n# 读入10个目录中的狗狗图片\ntraining_data('chihuahua',chihuahua_dir)\ntraining_data('japanese_spaniel',japanese_spaniel_dir)\ntraining_data('maltese',maltese_dir)\ntraining_data('pekinese',pekinese_dir)\ntraining_data('shitzu',shitzu_dir)\ntraining_data('blenheim_spaniel',blenheim_spaniel_dir)\ntraining_data('papillon',papillon_dir)\ntraining_data('toy_terrier',toy_terrier_dir)\ntraining_data('afghan_hound',afghan_hound_dir)\ntraining_data('basset',basset_dir)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:15.743195Z","iopub.execute_input":"2021-12-08T16:16:15.743949Z","iopub.status.idle":"2021-12-08T16:16:36.991336Z","shell.execute_reply.started":"2021-12-08T16:16:15.743873Z","shell.execute_reply":"2021-12-08T16:16:36.990408Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder # 导入标签编码工具\nfrom tensorflow.keras.utils import to_categorical # 导入One-hot编码工具\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y_label) # 标签编码\ny = to_categorical(y,10) # 将标签转换为One-hot编码\nX = np.array(X) # 将X从列表转换为张量数组\nX = X/255 # 将X张量归一化","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:36.995965Z","iopub.execute_input":"2021-12-08T16:16:36.996217Z","iopub.status.idle":"2021-12-08T16:16:44.193554Z","shell.execute_reply.started":"2021-12-08T16:16:36.996187Z","shell.execute_reply":"2021-12-08T16:16:44.192458Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print ('X张量的形状：', X.shape)\nprint ('X张量的第一个数据：', X[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:44.195343Z","iopub.execute_input":"2021-12-08T16:16:44.195640Z","iopub.status.idle":"2021-12-08T16:16:44.206925Z","shell.execute_reply.started":"2021-12-08T16:16:44.195585Z","shell.execute_reply":"2021-12-08T16:16:44.205155Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print ('y张量的形状：', y.shape)\nprint ('y张量的第一个数据：', y[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:44.208627Z","iopub.execute_input":"2021-12-08T16:16:44.208937Z","iopub.status.idle":"2021-12-08T16:16:44.229945Z","shell.execute_reply.started":"2021-12-08T16:16:44.208897Z","shell.execute_reply":"2021-12-08T16:16:44.229083Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt # 导入matplotlib\nimport random as rdm # 导入随机数工具\n# 随机显示几张可爱的狗狗图片吧\nfig,ax = plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        r = rdm.randint(0,len(X))\n        X[r] = X[r][...,::-1] #将图像通道从BGR调整为RGB，防止色彩失真\n        ax[i,j].imshow(X[r])\n        ax[i,j].set_title('Dog: '+y_label[r])\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:44.231599Z","iopub.execute_input":"2021-12-08T16:16:44.231994Z","iopub.status.idle":"2021-12-08T16:16:46.113389Z","shell.execute_reply.started":"2021-12-08T16:16:44.231949Z","shell.execute_reply":"2021-12-08T16:16:46.112492Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split # 导入拆分工具\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,\n                                                 random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:46.114564Z","iopub.execute_input":"2021-12-08T16:16:46.114815Z","iopub.status.idle":"2021-12-08T16:16:46.564493Z","shell.execute_reply.started":"2021-12-08T16:16:46.114780Z","shell.execute_reply":"2021-12-08T16:16:46.563401Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras import layers # 导入所有层\nfrom keras import models # 导入所有模型\ncnn = models.Sequential() # 贯序模型\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', # 卷积\n                        input_shape=(150, 150, 3))) \ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Flatten()) # 展平\ncnn.add(layers.Dense(512, activation='relu')) # 全连接\ncnn.add(layers.Dense(10, activation='softmax')) # 分类输出\ncnn.compile(loss='categorical_crossentropy', # 损失函数\n            optimizer='RMSprop', # 优化器\n            metrics=['acc']) # 评估指标","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:46.565759Z","iopub.execute_input":"2021-12-08T16:16:46.566835Z","iopub.status.idle":"2021-12-08T16:16:49.660620Z","shell.execute_reply.started":"2021-12-08T16:16:46.566782Z","shell.execute_reply":"2021-12-08T16:16:49.659735Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"history = cnn.fit(X_train,y_train, # 指定训练集\n                    epochs=50,     # 指定轮次\n                    batch_size=256, # 指定批量大小\n                    validation_data=(X_test,y_test)) # 指定验证集","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:16:49.668263Z","iopub.execute_input":"2021-12-08T16:16:49.668933Z","iopub.status.idle":"2021-12-08T16:17:37.828997Z","shell.execute_reply.started":"2021-12-08T16:16:49.668888Z","shell.execute_reply":"2021-12-08T16:17:37.828046Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**调整优化器**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import optimizers # 导入优化器\ncnn = models.Sequential() # 序贯模型\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', # 卷积\n                       input_shape=(150, 150, 3))) \ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.Dropout(0.5)) # Dropout\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.Dropout(0.5)) # Dropout\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(256, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Flatten()) # 展平\ncnn.add(layers.Dropout(0.5)) # Dropout\ncnn.add(layers.Dense(512, activation='relu')) # 全连接\ncnn.add(layers.Dense(10, activation='sigmoid')) # 分类输出\ncnn.compile(loss='categorical_crossentropy', # 损失函数\n            optimizer=optimizers.Adam(lr=1e-4), # 更新优化器并设定学习速率\n            metrics=['acc']) # 评估指标\nhistory = cnn.fit(X_train,y_train, # 指定训练集\n                  epochs=50,     # 指定轮次\n                  batch_size=256, # 指定批量大小\n                  validation_data=(X_test,y_test)) # 指定验证集","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:17:37.830855Z","iopub.execute_input":"2021-12-08T16:17:37.831356Z","iopub.status.idle":"2021-12-08T16:18:22.767232Z","shell.execute_reply.started":"2021-12-08T16:17:37.831293Z","shell.execute_reply":"2021-12-08T16:18:22.766223Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**添加Dropout层**","metadata":{}},{"cell_type":"code","source":"cnn = models.Sequential() # 序贯模型\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', # 卷积\n                       input_shape=(150, 150, 3))) \ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.Dropout(0.5)) # Dropout\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.Dropout(0.5)) # Dropout\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Conv2D(256, (3, 3), activation='relu')) # 卷积\ncnn.add(layers.MaxPooling2D((2, 2))) # 最大池化\ncnn.add(layers.Flatten()) # 展平\ncnn.add(layers.Dropout(0.5)) # Dropout\ncnn.add(layers.Dense(512, activation='relu')) # 全连接\ncnn.add(layers.Dense(10, activation='sigmoid')) # 分类输出\ncnn.compile(loss='categorical_crossentropy', # 损失函数\n            optimizer=optimizers.Adam(lr=1e-4), # 更新优化器并设定学习速率\n            metrics=['acc']) # 评估指标\nhistory = cnn.fit(X_train,y_train, # 指定训练集\n                  epochs=50,     # 指定轮次\n                  batch_size=256, # 指定批量大小\n                  validation_data=(X_test,y_test)) # 指定验证集","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:18:22.769083Z","iopub.execute_input":"2021-12-08T16:18:22.769334Z","iopub.status.idle":"2021-12-08T16:19:07.214465Z","shell.execute_reply.started":"2021-12-08T16:18:22.769299Z","shell.execute_reply":"2021-12-08T16:19:07.213483Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**数据增强**","metadata":{}},{"cell_type":"code","source":"# 定义一个数据增强器，并设定各种增强选项\nfrom keras.preprocessing.image import ImageDataGenerator\naugs_gen = ImageDataGenerator(\n           featurewise_center=False,\n           samplewise_center=False,         \n           featurewise_std_normalization=False,          \n           samplewise_std_normalization=False,  \n           zca_whitening=False, \n           rotation_range=10,  \n           zoom_range = 0.1, \n           width_shift_range=0.2,  \n           height_shift_range=0.2,\n           horizontal_flip=True,  \n           vertical_flip=False) \naugs_gen.fit(X_train) # 针对训练集拟合数据增强器","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:19:07.218073Z","iopub.execute_input":"2021-12-08T16:19:07.218903Z","iopub.status.idle":"2021-12-08T16:19:07.591946Z","shell.execute_reply.started":"2021-12-08T16:19:07.218817Z","shell.execute_reply":"2021-12-08T16:19:07.590912Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"history = cnn.fit( # 使用fit_generator\n    augs_gen.flow(X_train,y_train,batch_size=16), # 增强后的训练集\n#     validation_data  = (X_test,y_test), # 指定验证集\n#     validation_steps = 100, # 指定验证步长\n    steps_per_epoch  = 100, # 指定每轮步长\n    epochs = 50,  # 指定轮次\n    verbose = 1) # 指定是否显示训练过程中的信息","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:19:07.593606Z","iopub.execute_input":"2021-12-08T16:19:07.593927Z","iopub.status.idle":"2021-12-08T16:19:18.512731Z","shell.execute_reply.started":"2021-12-08T16:19:07.593871Z","shell.execute_reply":"2021-12-08T16:19:18.511667Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model # 导入模型保存工具\ncnn.save('../my_dog_cnn.h5')  # 创建一个HDF5格式的文件'my_dog_cnn.h5'\ndel cnn  # 删除当前模型\ncnn = load_model('../my_dog_cnn.h5') # 重新载入已经保存的模型","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:19:18.514481Z","iopub.execute_input":"2021-12-08T16:19:18.514903Z","iopub.status.idle":"2021-12-08T16:19:18.986235Z","shell.execute_reply.started":"2021-12-08T16:19:18.514860Z","shell.execute_reply":"2021-12-08T16:19:18.985109Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"** 绘制特征通道**","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model # 导入模型保存工具\nimport matplotlib.pyplot as plt # 导入matplotlib\nmodel = load_model('../my_dog_cnn.h5')# 载入刚才保存的模型\n# 绘制特征通道\nlayer_outputs = [layer.output for layer in model.layers[:16]]\nimage = X_train[0]\nimage = image.reshape(1, 150, 150, 3)\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(image)\nfirst_layer_activation = activations[0]\nplt.matshow(first_layer_activation[0, :, :, 2], cmap='viridis')\nplt.matshow(first_layer_activation[0, :, :, 3], cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:19:18.987747Z","iopub.execute_input":"2021-12-08T16:19:18.988155Z","iopub.status.idle":"2021-12-08T16:19:20.181372Z","shell.execute_reply.started":"2021-12-08T16:19:18.988078Z","shell.execute_reply":"2021-12-08T16:19:20.180205Z"},"trusted":true},"execution_count":16,"outputs":[]}]}