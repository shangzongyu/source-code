{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import numpy as np # 导入NumPy数学工具箱\nimport pandas as pd # 导入Pandas数据处理工具箱\ndf = pd.read_csv(\"../input/heart-dataset/heart.csv\")  # 读取文件\ndf.head() # 显示前5行数据","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns #导入seaborn画图工具箱\nsns.countplot(x=\"target\", data=df, palette=\"bwr\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 将某些特征转换为数值类型的哑变量\na = pd.get_dummies(df['cp'], prefix = \"cp\")\nb = pd.get_dummies(df['thal'], prefix = \"thal\")\nc = pd.get_dummies(df['slope'], prefix = \"slope\")\nframes = [df, a, b, c]\ndf = pd.concat(frames, axis = 1)\ndf.head()\ndf = df.drop(columns = ['cp', 'thal', 'slope'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 构建特征和标签集\ny = df.target.values\nX = df.drop(['target'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split # 拆分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 进行特征缩放\nfrom sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bagging with a decision tree regressor\nfrom sklearn.ensemble import BaggingClassifier \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import (f1_score, confusion_matrix) # 导入评估标准\ndt = BaggingClassifier(DecisionTreeClassifier()) # 只使用一棵决策树\ndt.fit(X_train, y_train) # 拟合模型\ny_pred = dt.predict(X_test) # 进行预测\nprint(\"决策树测试准确率: {:.2f}%\".format(dt.score(X_test, y_test)*100))\nprint(\"决策树测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\nbdt = BaggingClassifier(DecisionTreeClassifier()) #树的Bagging\nbdt.fit(X_train, y_train) # 拟合模型\ny_pred = bdt.predict(X_test) # 进行预测\nprint(\"决策树Bagging测试准确率: {:.2f}%\".format(bdt.score(X_test, y_test)*100))\nprint(\"决策树Bagging测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV # 导入网格搜索工具\n# 使用网格搜索优化参数\nbdt_param_grid = {\n    'base_estimator__max_depth' : [5,10,20,50,100],\n    'n_estimators' : [1, 5, 10, 50]}\nbdt_gs = GridSearchCV(BaggingClassifier(DecisionTreeClassifier()),\n                   param_grid = bdt_param_grid, scoring = 'f1',\n                   n_jobs= 10, verbose = 1)\nbdt_gs.fit(X_train, y_train) # 拟合模型\nbdt_gs = bdt_gs.best_estimator_ # 最佳模型\ny_pred = bdt.predict(X_test) # 进行预测\nprint(\"决策树Bagging测试准确率: {:.2f}%\".format(bdt_gs.score(X_test, y_test)*100)) \nprint(\"决策树Bagging测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier # 导入随机森林分类器\nrf = RandomForestClassifier() # 随机森林模型\n# 使用网格搜索优化参数\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n#               \"min_samples_split\": [2, 3, 10],\n#               \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True,False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\nrf_gs = GridSearchCV(rf,param_grid = rf_param_grid, \n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\nrf_gs.fit(X_train,y_train) # 拟合模型\nrf_gs = rf_gs.best_estimator_ # 最佳模型\ny_pred = rf_gs.predict(X_test) # 进行预测\nprint(\"随机森林测试准确率: {:.2f}%\".format(rf_gs.score(X_test, y_test)*100))\nprint(\"随机森林测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier # 导入AdaBoost模型\ndt = DecisionTreeClassifier() # 选择决策树分类器作为AdaBoost的基准算法\nada = AdaBoostClassifier(dt) # AdaBoost模型\n# 使用网格搜索优化参数\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n                  \"base_estimator__splitter\" :   [\"best\", \"random\"],\n                  \"base_estimator__random_state\" :   [7,9,10,12,15],\n                  \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n                  \"n_estimators\" :[1,2,5,10],\n                  \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\nada_gs = GridSearchCV(ada,param_grid = ada_param_grid, \n                        scoring=\"f1\", n_jobs= 10, verbose = 1)\nada_gs.fit(X_train,y_train) # 拟合模型\nada_gs = ada_gs.best_estimator_ # 最佳模型\ny_pred = ada_gs.predict(X_test) # 进行预测\nprint(\"Adaboost测试准确率: {:.2f}%\".format(ada_gs.score(X_test, y_test)*100))\nprint(\"Adaboost测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier # 导入GBDT分类器\ngb = GradientBoostingClassifier() # GBDT分类器\n# 使用网格搜索优化参数\ngb_param_grid = {'loss' : [\"deviance\"],\n                 'n_estimators' : [100,200,300],\n                 'learning_rate': [0.1, 0.05, 0.01],\n                 'max_depth': [4, 8],\n                 'min_samples_leaf': [100,150],\n                 'max_features': [0.3, 0.1]}\ngb_gs = GridSearchCV(gb,param_grid = gb_param_grid,\n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\ngb_gs.fit(X_train,y_train) # 拟合模型\ngb_gs = gb_gs.best_estimator_ # 最佳模型\ny_pred = gb_gs.predict(X_test) # 进行预测\nprint(\"GBDT测试准确率: {:.2f}%\".format(gb_gs.score(X_test, y_test)*100))\nprint(\"GBDT测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier # 导入XGB分类器\nxgb = XGBClassifier() # XGB分类器\n# 使用网格搜索优化参数\nxgb_param_grid = {'min_child_weight': [1, 5, 10],\n                  'gamma': [0.5, 1, 1.5, 2, 5],\n                  'subsample': [0.6, 0.8, 1.0],\n                  'colsample_bytree': [0.6, 0.8, 1.0],\n                  'max_depth': [3, 4, 5]}\nxgb_gs = GridSearchCV(xgb,param_grid = xgb_param_grid,  \n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\nxgb_gs.fit(X_train,y_train) # 拟合模型\nxgb_gs = xgb_gs.best_estimator_ # 最佳模型\ny_pred = xgb_gs.predict(X_test) # 进行预测\nprint(\"XGB测试准确率: {:.2f}%\".format(xgb_gs.score(X_test, y_test)*100))\nprint(\"XGB测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}