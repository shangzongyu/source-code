{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np #导入NumPy数学工具箱\nimport pandas as pd #导入Pandas数据处理工具箱\n# 读入数据并显示前面几行的内容，这是为了确保我们的文件读入正确性\n# 示例代码是在Kaggle中数据集中读入文件，如果在本机中需要指定具体本地路径\ndf_ads = pd.read_csv('../input/advertising-simple-dataset/advertising.csv')\ndf_ads.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-09T08:48:06.194966Z","iopub.execute_input":"2021-12-09T08:48:06.195468Z","iopub.status.idle":"2021-12-09T08:48:06.261060Z","shell.execute_reply.started":"2021-12-09T08:48:06.195338Z","shell.execute_reply":"2021-12-09T08:48:06.260485Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"X = np.array(df_ads) # 构建特征集，含全部特征\nX = np.delete(X, [3], axis = 1) # 删除掉标签\ny = np.array(df_ads.sales) #构建标签集，销售金额\nprint (\"张量X的阶:\",X.ndim)\nprint (\"张量X的形状:\", X.shape)\nprint (X)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:06.262476Z","iopub.execute_input":"2021-12-09T08:48:06.262801Z","iopub.status.idle":"2021-12-09T08:48:06.281789Z","shell.execute_reply.started":"2021-12-09T08:48:06.262774Z","shell.execute_reply":"2021-12-09T08:48:06.280647Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"y = y.reshape(-1,1) #通过reshape函数把向量转换为矩阵，-1就是len(y),返回样本个数\nprint (\"张量y的形状:\", y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:06.285402Z","iopub.execute_input":"2021-12-09T08:48:06.285654Z","iopub.status.idle":"2021-12-09T08:48:06.294010Z","shell.execute_reply.started":"2021-12-09T08:48:06.285626Z","shell.execute_reply":"2021-12-09T08:48:06.293350Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 将数据集进行80%（训练集）和20%（验证集）的分割\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                   test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:06.294921Z","iopub.execute_input":"2021-12-09T08:48:06.295759Z","iopub.status.idle":"2021-12-09T08:48:07.384706Z","shell.execute_reply.started":"2021-12-09T08:48:06.295713Z","shell.execute_reply":"2021-12-09T08:48:07.383823Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def scaler(train, test): # 定义归一化函数 ，进行数据压缩    \n    # 数据的压缩\n    min = train.min(axis=0) # 训练集最小值\n    max = train.max(axis=0) # 训练集最大值\n    gap = max - min # 最大值和最小值的差\n    train -= min # 所有数据减最小值\n    train /= gap # 所有数据除以大小值差\n    test -= min #把训练集最小值应用于测试集\n    test /= gap #把训练集大小值差应用于测试集\n    return train, test # 返回压缩后的数据","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.387656Z","iopub.execute_input":"2021-12-09T08:48:07.387984Z","iopub.status.idle":"2021-12-09T08:48:07.394446Z","shell.execute_reply.started":"2021-12-09T08:48:07.387942Z","shell.execute_reply":"2021-12-09T08:48:07.393382Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def min_max_gap(train): # 计算训练集最大，最小值以及他们的差，用于后面反归一化过程\n    min = train.min(axis=0) # 训练集最小值\n    max = train.max(axis=0) # 训练集最大值\n    gap = max - min # 最大值和最小值的差\n    return min, max, gap\n    \ny_min, y_max, y_gap = min_max_gap(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.396013Z","iopub.execute_input":"2021-12-09T08:48:07.396466Z","iopub.status.idle":"2021-12-09T08:48:07.406190Z","shell.execute_reply.started":"2021-12-09T08:48:07.396431Z","shell.execute_reply":"2021-12-09T08:48:07.405184Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train_original = X_train.copy() # 保留一份训练集数据副本，用于对要预测数据归一化","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.407799Z","iopub.execute_input":"2021-12-09T08:48:07.408070Z","iopub.status.idle":"2021-12-09T08:48:07.418994Z","shell.execute_reply.started":"2021-12-09T08:48:07.408037Z","shell.execute_reply":"2021-12-09T08:48:07.418288Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train,X_test = scaler(X_train,X_test) # 对特征归一化\ny_train,y_test = scaler(y_train,y_test) # 对标签也归一化","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.420482Z","iopub.execute_input":"2021-12-09T08:48:07.420710Z","iopub.status.idle":"2021-12-09T08:48:07.430008Z","shell.execute_reply.started":"2021-12-09T08:48:07.420683Z","shell.execute_reply":"2021-12-09T08:48:07.429331Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x0_train = np.ones((len(X_train),1)) # 构造X_train长度的全1数组配合对Bias的点积\nX_train = np.append(x0_train, X_train, axis=1) #把X增加一系列的1\nx0_test = np.ones((len(X_test),1)) # 构造X_test长度的全1数组配合对Bias的点积\nX_test = np.append(x0_test, X_test, axis=1) #把X增加一系列的1\nprint (\"张量X的形状:\", X_train.shape)\nprint (X_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.431024Z","iopub.execute_input":"2021-12-09T08:48:07.431307Z","iopub.status.idle":"2021-12-09T08:48:07.455217Z","shell.execute_reply.started":"2021-12-09T08:48:07.431267Z","shell.execute_reply":"2021-12-09T08:48:07.454320Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def loss_function(X, y, W): # 手工定义一个MSE均方误差函数,W此时是一个向量\n    y_hat = X.dot(W.T) # 点积运算 h(x)=w_0*x_0 + w_1*x_1 + w_2*x_2 + w_3*x_3    \n    loss = y_hat.reshape((len(y_hat),1))-y # 中间过程,求出当前W和真值的差异\n    cost = np.sum(loss**2)/(2*len(X)) # 这是平方求和过程, 均方误差函数的代码实现\n    return cost # 返回当前模型的均方误差值","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.456561Z","iopub.execute_input":"2021-12-09T08:48:07.456875Z","iopub.status.idle":"2021-12-09T08:48:07.466564Z","shell.execute_reply.started":"2021-12-09T08:48:07.456840Z","shell.execute_reply":"2021-12-09T08:48:07.465588Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def gradient_descent(X, y, W, lr, iterations): # 定义梯度下降函数\n    l_history = np.zeros(iterations) # 初始化记录梯度下降过程中损失的数组\n    W_history = np.zeros((iterations,len(W))) # 初始化权重数组 \n    for iter in range(iterations): # 进行梯度下降的迭代，就是下多少级台阶\n        y_hat = X.dot(W.T) # 这个是向量化运行实现的假设函数   \n        loss = y_hat.reshape((len(y_hat),1))-y # 中间过程, y_hat和y真值的差\n        derivative_W = X.T.dot(loss)/len(X) #求出多项式的梯度向量\n        derivative_W = derivative_W.reshape(len(W)) \n        W = W - lr*derivative_W # 结合下降速率更新权重\n        l_history[iter] = loss_function(X, y, W) # 损失的历史记录 \n        W_history[iter] = W # 梯度下降过程中权重的历史记录\n    return l_history, W_history # 返回梯度下降过程数据","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.468164Z","iopub.execute_input":"2021-12-09T08:48:07.468392Z","iopub.status.idle":"2021-12-09T08:48:07.479654Z","shell.execute_reply.started":"2021-12-09T08:48:07.468364Z","shell.execute_reply":"2021-12-09T08:48:07.478918Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#首先确定参数的初始值\niterations = 300; # 迭代300次\nalpha = 0.15; #学习速率设为0.15\nweight = np.array([0.5,1,1,1]) # 权重向量，w[0] = bias\n#计算一下初始值的损失\nprint ('当前损失：',loss_function(X_train, y_train, weight))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.481265Z","iopub.execute_input":"2021-12-09T08:48:07.481771Z","iopub.status.idle":"2021-12-09T08:48:07.493586Z","shell.execute_reply.started":"2021-12-09T08:48:07.481727Z","shell.execute_reply":"2021-12-09T08:48:07.492190Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# 定义线性回归模型\ndef linear_regression(X, y, weight, alpha, iterations): \n    loss_history, weight_history = gradient_descent(X, y, \n                                                    weight, \n                                                    alpha, iterations)\n    print(\"训练最终损失:\", loss_history[-1]) # 打印最终损失\n    y_pred = X.dot(weight_history[-1]) # 进行预测\n    traning_acc = 100 - np.mean(np.abs(y_pred - y))*100 # 计算准确率\n    print(\"线性回归训练准确率: {:.2f}%\".format(traning_acc))  # 打印准确率\n    return loss_history, weight_history # 返回训练历史记录","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.495331Z","iopub.execute_input":"2021-12-09T08:48:07.495844Z","iopub.status.idle":"2021-12-09T08:48:07.508230Z","shell.execute_reply.started":"2021-12-09T08:48:07.495800Z","shell.execute_reply":"2021-12-09T08:48:07.507138Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# 调用刚才定义的线性回归模型\nloss_history, weight_history = linear_regression(X_train, y_train,\n                           weight, alpha, iterations) #训练机器","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.510577Z","iopub.execute_input":"2021-12-09T08:48:07.511486Z","iopub.status.idle":"2021-12-09T08:48:07.535554Z","shell.execute_reply.started":"2021-12-09T08:48:07.511451Z","shell.execute_reply":"2021-12-09T08:48:07.534828Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(\"权重历史记录：\", weight_history)\nprint(\"损失历史记录：\", loss_history)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.536792Z","iopub.execute_input":"2021-12-09T08:48:07.537836Z","iopub.status.idle":"2021-12-09T08:48:07.548961Z","shell.execute_reply.started":"2021-12-09T08:48:07.537769Z","shell.execute_reply":"2021-12-09T08:48:07.548351Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_plan = [250,50,50] # 要预测的X特征数据\nX_train,X_plan = scaler(X_train_original,X_plan) # 对预测数据也要归一化缩放\nX_plan = np.append([1], X_plan ) # 加一个哑特征X0 = 1\ny_plan = np.dot(weight_history[-1],X_plan) # [-1] 即模型收敛时的权重\n# 对预测结果要做反向缩放，才能得到与原始广告费用对应的预测值\ny_value = y_plan*y_gap + y_min # y_gap是当前y_train中最大值和最小值的差，y_min是最小值\nprint (\"预计商品销售额： \",y_value, \"千元\") ","metadata":{"execution":{"iopub.status.busy":"2021-12-09T08:48:07.549962Z","iopub.execute_input":"2021-12-09T08:48:07.550782Z","iopub.status.idle":"2021-12-09T08:48:07.568336Z","shell.execute_reply.started":"2021-12-09T08:48:07.550746Z","shell.execute_reply":"2021-12-09T08:48:07.567653Z"},"trusted":true},"execution_count":16,"outputs":[]}]}